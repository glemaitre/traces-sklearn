{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4297fc",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluating a predictive model\n",
    "\n",
    "This notebook will:\n",
    "\n",
    "- Introduce linear models for regression tasks\n",
    "- Demonstrate scikit-learn's user API\n",
    "- Explain training and testing error concepts\n",
    "- Cover cross-validation techniques\n",
    "- Compare models against baselines\n",
    "\n",
    "## Linear regression introduction\n",
    "\n",
    "Let's start with linear regression fundamentals. We'll use only NumPy initially,\n",
    "before introducing scikit-learn. First, we load our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d0690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using JupyterLite, you will need to uncomment and install the `skrub` package.\n",
    "%pip install skrub\n",
    "import matplotlib.pyplot as plt\n",
    "import skrub\n",
    "skrub.patch_display()  # make nice display for pandas tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb59365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../datasets/penguins_regression.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110cf89",
   "metadata": {},
   "source": [
    "\n",
    "Our dataset contains penguin flipper lengths and body masses. We want to predict a\n",
    "penguin's body mass from its flipper length. Since we predict a continuous value,\n",
    "this is a regression problem.\n",
    "\n",
    "Let's visualize the relationship between these measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ax = data.plot.scatter(x=data.columns[0], y=data.columns[1])\n",
    "ax.set_title(\"Can I predict penguins' body mass?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf62ee4",
   "metadata": {},
   "source": [
    "\n",
    "The data shows a clear linear trend - longer flippers correlate with heavier penguins.\n",
    "We'll model this relationship linearly.\n",
    "\n",
    "In this example:\n",
    "\n",
    "- Flipper length serves as our feature (predictor variable)\n",
    "- Body mass is our target (variable to predict)\n",
    "\n",
    "Each (flipper length, body mass) pair forms a sample. We train our model on these\n",
    "feature/target pairs. At prediction time, we use only features to predict potential\n",
    "targets. To evaluate our model, we compare its predictions against known targets.\n",
    "\n",
    "Throughout this notebook, we use:\n",
    "- `X`: feature matrix with shape `(n_samples, n_features)`\n",
    "- `y`: target vector with shape `(n_samples,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dae3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[[\"Flipper Length (mm)\"]], data[[\"Body Mass (g)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ce56e",
   "metadata": {},
   "source": [
    "\n",
    "We model the X-y relationship linearly as:\n",
    "\n",
    "$$\n",
    "y = X \\beta\n",
    "$$\n",
    "\n",
    "where $\\beta$ represents our model coefficients. For all features, this expands to:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n\n",
    "$$\n",
    "\n",
    "Here we have only one feature coefficient $\\beta_1$ for flipper length.\n",
    "\n",
    "Finding the optimal $\\beta$ means finding values that minimize prediction error. We\n",
    "calculate $\\beta$ using:\n",
    "\n",
    "$$\n",
    "X^T y = X^T X \\beta\n",
    "$$\n",
    "\n",
    "which gives us:\n",
    "\n",
    "$$\n",
    "\\beta = (X^T X)^{-1} X^T y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888c378",
   "metadata": {},
   "source": [
    "\n",
    "**EXERCISE**\n",
    "\n",
    "1. Use NumPy to find $\\beta$ ($\\beta_0$ and $\\beta_1$) using the normal equation\n",
    "2. Calculate predictions using your $\\beta$ values and X\n",
    "3. Plot the original data (X vs y) and overlay your model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ba1b36",
   "metadata": {},
   "source": [
    "\n",
    "## Scikit-learn API introduction\n",
    "\n",
    "Scikit-learn uses Python classes to maintain model state. These classes provide:\n",
    "\n",
    "- A `fit` method to learn parameters\n",
    "- A `predict` method to generate predictions\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Create a Python class that implements the linear model from above with:\n",
    "\n",
    "- A `fit` method to compute $\\beta$\n",
    "- A `predict` method that outputs predictions for input X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cafbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b2c56",
   "metadata": {},
   "source": [
    "\n",
    "Now let's use scikit-learn's built-in `LinearRegression` model instead of our\n",
    "implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7247862a",
   "metadata": {},
   "source": [
    "\n",
    "Scikit-learn models store fitted parameters as attributes ending in underscore.\n",
    "Our linear model stores `coef_` and `intercept_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ebd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce920de",
   "metadata": {},
   "source": [
    "\n",
    "## Cross-validation for proper model evaluation\n",
    "\n",
    "Let's evaluate our model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e474c3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "score = r2_score(y, model.predict(X))\n",
    "print(f\"Model score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78153a4",
   "metadata": {},
   "source": [
    "\n",
    "This evaluation has a flaw. A model that simply memorizes training data would score\n",
    "perfectly. We need separate training and testing datasets to truly assess how well\n",
    "our model generalizes to new data. The training error measures model fit, while\n",
    "testing error measures generalization ability.\n",
    "\n",
    "Let's split our data into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08922e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a442ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = r2_score(y_train, model.predict(X_train))\n",
    "print(f\"Training score: {train_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85863378",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = r2_score(y_test, model.predict(X_test))\n",
    "print(f\"Testing score: {test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba39f88",
   "metadata": {},
   "source": [
    "\n",
    "Our model performs slightly worse on test data than training data. For comparison,\n",
    "let's examine a decision tree model which can show more dramatic differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a520999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = r2_score(y_train, model.predict(X_train))\n",
    "print(f\"Training score: {train_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944cda40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = r2_score(y_test, model.predict(X_test))\n",
    "print(f\"Testing score: {test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498fb3de",
   "metadata": {},
   "source": [
    "\n",
    "Returning to our linear model: while we see small differences between training and\n",
    "testing scores, we can't determine if these differences are significant or just\n",
    "random variation from our data split. Cross-validation helps us estimate score\n",
    "distributions rather than single points.\n",
    "\n",
    "Cross-validation repeatedly evaluates the model using different train/test splits\n",
    "to account for variation in both fitting and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd8b881",
   "metadata": {},
   "source": [
    "\n",
    "Scikit-learn's `cross_validate` function handles this repeated evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ecff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(\n",
    "    model, X, y, cv=cv,\n",
    "    scoring=\"r2\",\n",
    "    return_train_score=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results[[\"train_score\", \"test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[[\"train_score\", \"test_score\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ab81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[[\"train_score\", \"test_score\"]].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcbb7ee",
   "metadata": {},
   "source": [
    "\n",
    "Our results show similar train and test scores, though test scores vary more.\n",
    "Let's use repeated k-fold cross-validation to get more estimates and visualize\n",
    "the score distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "cv = RepeatedKFold(n_repeats=10, n_splits=3, random_state=42)\n",
    "cv_results = cross_validate(\n",
    "    model, X, y, cv=cv,\n",
    "    scoring=\"r2\",\n",
    "    return_train_score=True\n",
    ")\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results[[\"train_score\", \"test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = cv_results[[\"train_score\", \"test_score\"]].plot.hist(alpha=0.7)\n",
    "ax.set(xlim=(0, 1), title=\"Distribution of the scores with repeated k-fold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b20876",
   "metadata": {},
   "source": [
    "\n",
    "The similar performance on training and testing sets with low variation indicates\n",
    "our model generalizes well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3195b8b",
   "metadata": {},
   "source": [
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Repeat the cross-validation using `KFold` with `shuffle=False`. Compare and explain\n",
    "the differences from our previous analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caffbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb1471",
   "metadata": {},
   "source": [
    "\n",
    "## Baseline model comparison\n",
    "\n",
    "It is common to compare the performance of a new model against simple models.\n",
    "These baseline models do not necessarily have to learn anything from the data.\n",
    "But they provide a reference to compare against.\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Compare your linear model against such a baseline:\n",
    "\n",
    "1. Use cross-validation to get 30+ score estimates\n",
    "2. Try a `DummyRegressor` that predicts the mean target value of the training set\n",
    "3. Use `permutation_test_score` function to estimate the performance of a random model\n",
    "4. Plot test score distributions for all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb9e9f4",
   "metadata": {},
   "source": [
    "\n",
    "## Model uncertainty evaluation\n",
    "\n",
    "Cross-validation evaluates uncertainty in the full fit/predict process by training\n",
    "different models on each cross-validation split.\n",
    "\n",
    "For a single model, we can evaluate prediction uncertainty through bootstrapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48047733",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62916a",
   "metadata": {},
   "source": [
    "\n",
    "**EXERCISE**\n",
    "\n",
    "1. Generate model predictions on the test set\n",
    "2. Create 100 bootstrap prediction samples using `np.random.choice`\n",
    "3. Plot the bootstrap sample distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df2a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
