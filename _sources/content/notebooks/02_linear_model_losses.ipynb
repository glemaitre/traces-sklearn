{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da968980",
   "metadata": {},
   "source": [
    "\n",
    "# Losses\n",
    "\n",
    "This notebook explores linear models and loss functions in depth. We use the previous\n",
    "regression problem that models the relationship between penguins' flipper length and\n",
    "body mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b32500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using JupyterLite, you will need to uncomment and install the `skrub` package.\n",
    "%pip install skrub\n",
    "import matplotlib.pyplot as plt\n",
    "import skrub\n",
    "\n",
    "skrub.patch_display()  # make nice display for pandas tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb1ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../datasets/penguins_regression.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee24ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.scatter(x=\"Flipper Length (mm)\", y=\"Body Mass (g)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c233c9",
   "metadata": {},
   "source": [
    "\n",
    "The data shows a clear linear relationship between flipper length and body mass. We\n",
    "use body mass as our target variable and flipper length as our feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9fb861",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[[\"Flipper Length (mm)\"]], data[\"Body Mass (g)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0450d5a",
   "metadata": {},
   "source": [
    "\n",
    "In the previous notebook, we used scikit-learn's `LinearRegression` to learn model\n",
    "parameters from data with `fit` and make predictions with `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bcd392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "predicted_target = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9283c0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "ax = data.plot.scatter(x=\"Flipper Length (mm)\", y=\"Body Mass (g)\")\n",
    "ax.plot(\n",
    "    X, predicted_target, label=model.__class__.__name__, color=\"tab:orange\", linewidth=4\n",
    ")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be3bcb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "The linear regression model minimizes the error between true and predicted targets.\n",
    "A general term to describe this error is \"loss function\". For the linear regression,\n",
    "from scikit-learn, it specifically minimizes the least squared error:\n",
    "\n",
    "$$\n",
    "loss = (y - \\hat{y})^2\n",
    "$$\n",
    "\n",
    "or equivalently:\n",
    "\n",
    "$$\n",
    "loss = (y - X \\beta)^2\n",
    "$$\n",
    "\n",
    "Let's visualize this loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_loss(true_target, predicted_target):\n",
    "    loss = (true_target - predicted_target) ** 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "xmin, xmax = -2, 2\n",
    "xx = np.linspace(xmin, xmax, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xx, se_loss(0, xx), label=\"SE loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff70669",
   "metadata": {},
   "source": [
    "\n",
    "The bell shape of the loss function heavily penalizes large errors, which\n",
    "significantly impacts the model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe99ad6",
   "metadata": {},
   "source": [
    "\n",
    "**EXERCISE**\n",
    "\n",
    "1. Add an outlier to the dataset: a penguin with 230 mm flipper length and 300 g\n",
    "   body mass\n",
    "2. Plot the updated dataset\n",
    "3. Fit a `LinearRegression` model on this dataset, using `sample_weight`\n",
    "   to give the outlier 10x more weight than other samples\n",
    "4. Plot the model predictions\n",
    "\n",
    "How does the outlier affect the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8df649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba26cce",
   "metadata": {},
   "source": [
    "\n",
    "Instead of squared loss, we now use the Huber loss through scikit-learn's\n",
    "`HuberRegressor`. We fit this model similarly to our previous approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "sample_weight = np.ones_like(y)\n",
    "sample_weight[-1] = 10\n",
    "model = HuberRegressor()\n",
    "model.fit(X, y, sample_weight=sample_weight)\n",
    "predicted_target = model.predict(X)\n",
    "# -\n",
    "\n",
    "ax = data.plot.scatter(x=\"Flipper Length (mm)\", y=\"Body Mass (g)\")\n",
    "ax.plot(X, predicted_target, label=model.__class__.__name__, color=\"black\", linewidth=4)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514ac2b",
   "metadata": {},
   "source": [
    "\n",
    "The Huber loss gives less weight to outliers compared to least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2928c",
   "metadata": {},
   "source": [
    "\n",
    "**EXERCISE**\n",
    "\n",
    "1. Read the `HuberRegressor` documentation\n",
    "2. Create a `huber_loss` function similar to `se_loss`\n",
    "3. Create an absolute loss function\n",
    "\n",
    "Explain why outliers affect Huber regression less than ordinary least squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a65aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ab37ef",
   "metadata": {},
   "source": [
    "\n",
    "Huber and absolute losses penalize outliers less severely. This makes outliers less\n",
    "influential when finding the optimal $\\beta$ parameters. The `HuberRegressor`\n",
    "estimates the median rather than the mean.\n",
    "\n",
    "For other quantiles, scikit-learn offers the `QuantileRegressor`. It minimizes the\n",
    "pinball loss to estimate specific quantiles. Here's how to estimate the median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5dae41",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "model = QuantileRegressor(quantile=0.5)\n",
    "model.fit(X, y, sample_weight=sample_weight)\n",
    "predicted_target = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bbe069",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data.plot.scatter(x=\"Flipper Length (mm)\", y=\"Body Mass (g)\")\n",
    "ax.plot(X, predicted_target, label=model.__class__.__name__, color=\"black\", linewidth=4)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d40b6f",
   "metadata": {},
   "source": [
    "\n",
    "The `QuantileRegressor` enables estimation of confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuantileRegressor(quantile=0.5, solver=\"highs\")\n",
    "model.fit(X, y, sample_weight=sample_weight)\n",
    "predicted_target_median = model.predict(X)\n",
    "\n",
    "model.set_params(quantile=0.90)\n",
    "model.fit(X, y, sample_weight=sample_weight)\n",
    "predicted_target_90 = model.predict(X)\n",
    "\n",
    "model.set_params(quantile=0.10)\n",
    "model.fit(X, y, sample_weight=sample_weight)\n",
    "predicted_target_10 = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data.plot.scatter(x=\"Flipper Length (mm)\", y=\"Body Mass (g)\")\n",
    "ax.plot(\n",
    "    X,\n",
    "    predicted_target_median,\n",
    "    label=f\"{model.__class__.__name__} - median\",\n",
    "    color=\"black\",\n",
    "    linewidth=4,\n",
    ")\n",
    "ax.plot(\n",
    "    X,\n",
    "    predicted_target_90,\n",
    "    label=f\"{model.__class__.__name__} - 90th percentile\",\n",
    "    color=\"tab:orange\",\n",
    "    linewidth=4,\n",
    ")\n",
    "ax.plot(\n",
    "    X,\n",
    "    predicted_target_10,\n",
    "    label=f\"{model.__class__.__name__} - 10th percentile\",\n",
    "    color=\"tab:green\",\n",
    "    linewidth=4,\n",
    ")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0fcf3",
   "metadata": {},
   "source": [
    "\n",
    "This plot shows an 80% confidence interval around the median using the 10th and 90th\n",
    "percentiles."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
